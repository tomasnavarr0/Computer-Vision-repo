{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "qL_5RK7ZbcDX"
      },
      "outputs": [],
      "source": [
        "!pip install -q mediapy\n",
        "import mediapy as media\n",
        "import cv2\n",
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "url = '/content/cochera.mp4'\n",
        "video = media.read_video(url)\n",
        "media.show_video(video)"
      ],
      "metadata": {
        "id": "ycAyzVoibzga"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lo que yo hice"
      ],
      "metadata": {
        "id": "vPXndh8IreFV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Función para oscurecer una imagen:\n",
        "def process_image(new_image, prev_image, **kwargs):\n",
        "    # Convertir la imagen a float32\n",
        "    new_image_float = new_image.astype(np.float32)\n",
        "\n",
        "    # Reducir el brillo de la imagen a la mitad\n",
        "    new_image_float *= 0.5\n",
        "\n",
        "    # Convertir la imagen de vuelta a uint8\n",
        "    new_image_uint8 = np.clip(new_image_float, 0, 255).astype(np.uint8)\n",
        "\n",
        "    return new_image_uint8\n"
      ],
      "metadata": {
        "id": "fcNJuPOrjb9H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def draw_contours(frame, contours, color=(0, 255, 0), thickness=1):\n",
        "    # Comprobar si la imagen es en escala de grises (1 canal)\n",
        "    if len(frame.shape) == 2 or frame.shape[2] == 1:\n",
        "        # Convertir la imagen de escala de grises a color (3 canales)\n",
        "        result_image = cv2.cvtColor(frame, cv2.COLOR_GRAY2BGR)\n",
        "    else:\n",
        "        # Si ya es una imagen de color, simplemente hacer una copia\n",
        "        result_image = frame.copy()\n",
        "\n",
        "    # Dibujar cada contorno en la imagen\n",
        "    for contour in contours:\n",
        "        # Obtener el rectángulo delimitador para cada contorno\n",
        "        x, y, w, h = cv2.boundingRect(contour)\n",
        "        # Dibujar el rectángulo\n",
        "        cv2.rectangle(result_image, (x, y), (x + w, y + h), color, thickness)\n",
        "\n",
        "    return result_image"
      ],
      "metadata": {
        "id": "rRu6xrDyjdym"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Función para procesar un video:\n",
        "def video_processor(filename_in, filename_out, process_func, max_time=10, **kwargs):\n",
        "    # Abrir el video de entrada para lectura\n",
        "    with media.VideoReader(filename_in) as r:\n",
        "        # Crear un archivo de video de salida\n",
        "        with media.VideoWriter(filename_out, shape=r.shape, fps=r.fps, bps=r.bps) as w:\n",
        "            count = 0  # Inicializar contador de fotogramas\n",
        "            prev_image = None  # Inicializar la imagen previa\n",
        "\n",
        "            # Iterar sobre cada imagen (fotograma) del video\n",
        "            for image in r:\n",
        "                new_image = media.to_uint8(image)  # Convertir la imagen a formato flotante\n",
        "\n",
        "                # Comprobar si es la primera imagen\n",
        "                if prev_image is None:\n",
        "                    prev_image = new_image.copy()\n",
        "\n",
        "                # Procesar la imagen utilizando la función dada\n",
        "                processed_image = process_func(new_image, prev_image, **kwargs)\n",
        "\n",
        "                # Añadir la imagen procesada al video de salida\n",
        "                w.add_image(processed_image)\n",
        "\n",
        "                # Actualizar la imagen previa\n",
        "                prev_image = new_image.copy()\n",
        "\n",
        "                # Incrementar el contador de fotogramas\n",
        "                count += 1\n",
        "\n",
        "                # Detener el proceso si se alcanza el tiempo máximo\n",
        "                if count >= max_time * r.fps:\n",
        "                    break\n",
        "\n"
      ],
      "metadata": {
        "id": "B9--VDn5eUhK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "## Nombres de los archivos de video de entrada y salida\n",
        "filename_in = '/content/cochera.mp4'\n",
        "filename_out = '/content/cochera_dark.mp4'\n",
        "#\n",
        "## Llamar a la función para procesar el video\n",
        "video_processor(filename_in, filename_out, process_image, 10)\n",
        "#\n",
        "# Mostrar el video resultante\n",
        "media.show_video(media.read_video(filename_out), fps=30)"
      ],
      "metadata": {
        "id": "-ZLPZduVeqFS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_frame_difference(new_image, prev_image, **kwargs):\n",
        "    # Convertir las imágenes a escala de grises\n",
        "    new_gray = cv2.cvtColor(new_image, cv2.COLOR_RGB2GRAY)\n",
        "    prev_gray = cv2.cvtColor(prev_image, cv2.COLOR_RGB2GRAY)\n",
        "\n",
        "    # Calcular la diferencia absoluta entre los fotogramas actual y anterior\n",
        "    frame_diff = cv2.absdiff(new_gray, prev_gray)\n",
        "\n",
        "    # Normalizar la imagen de diferencia\n",
        "    norm_diff = cv2.normalize(frame_diff, None, 0, 255, cv2.NORM_MINMAX)\n",
        "\n",
        "    # Umbralizar la imagen para resaltar las diferencias\n",
        "    _, thresh = cv2.threshold(norm_diff, 150, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "    # Convertir la imagen umbralizada a color para mantener la consistencia con el video original\n",
        "    thresh_color = cv2.cvtColor(thresh, cv2.COLOR_GRAY2RGB)\n",
        "\n",
        "    return thresh_color\n",
        "\n"
      ],
      "metadata": {
        "id": "-ogpyWGJeIFD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab.patches import cv2_imshow"
      ],
      "metadata": {
        "id": "WXf43pUDj4UO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Nombres de los archivos de video de entrada y salida\n",
        "filename_in = '/content/cochera.mp4'\n",
        "filename_out = \"cochera_frame_diff.mp4\"\n",
        "\n",
        "# Llamar a la función para procesar el video\n",
        "video_processor(filename_in, filename_out, process_frame_difference, 10)\n",
        "\n",
        "# Mostrar el video resultante\n",
        "media.show_video(media.read_video(filename_out), fps=30)"
      ],
      "metadata": {
        "id": "Z8CZX7CVgVOl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Función actualizada para detectar movimientos y dibujar cuadros delimitadores:\n",
        "def process_frame_difference_full(new_image, prev_image, **kwargs):\n",
        "    # Convertir las imágenes a escala de grises\n",
        "    new_gray = cv2.cvtColor(new_image, cv2.COLOR_RGB2GRAY)\n",
        "    prev_gray = cv2.cvtColor(prev_image, cv2.COLOR_RGB2GRAY)\n",
        "\n",
        "    # Calcular la diferencia absoluta entre los fotogramas actual y anterior\n",
        "    frame_diff = cv2.absdiff(new_gray, prev_gray)\n",
        "\n",
        "    # Normalizar la imagen de diferencia\n",
        "    norm_diff = cv2.normalize(frame_diff, None, 0, 255, cv2.NORM_MINMAX)\n",
        "\n",
        "    # Umbralizar la imagen para resaltar las diferencias\n",
        "    _, thresh = cv2.threshold(norm_diff, 150, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "    # Dilatar la imagen umbralizada para mejorar la detección de contornos\n",
        "    kernel = np.ones((9,9),np.uint8)\n",
        "    dilated = cv2.dilate(thresh, kernel, iterations = 1)\n",
        "    #cv2_imshow(dilated)\n",
        "    # Convertir la imagen dilatada a formato adecuado para findContours\n",
        "    dilated = dilated.astype(np.uint8)\n",
        "\n",
        "    # Encontrar contornos en la imagen dilatada\n",
        "    contours, _ = cv2.findContours(dilated, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "    # Dibujar cuadros delimitadores alrededor de los contornos\n",
        "    if kwargs.get('draw_mode', 0) == 0:\n",
        "      result_image = draw_contours(new_image, contours)\n",
        "    elif kwargs.get('draw_mode', 0) == 1:\n",
        "      result_image = draw_contours(thresh, contours)\n",
        "\n",
        "    return result_image\n",
        "\n"
      ],
      "metadata": {
        "id": "Z6fL0Ck5g5Gt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Nombres de los archivos de video de entrada y salida\n",
        "filename_in = '/content/cochera.mp4'\n",
        "filename_out = 'cochera_frame_diff_full.mp4'\n",
        "\n",
        "# Llamar a la función para procesar el video\n",
        "video_processor(filename_in, filename_out, process_frame_difference_full,\n",
        "                max_time=10, draw_mode=1)\n",
        "\n",
        "# Mostrar el video resultante\n",
        "media.show_video(media.read_video(filename_out), fps=30)\n",
        "\n",
        "# Llamar a la función para procesar el video\n",
        "filename_out = 'frame_difference_full_2.mp4'\n",
        "video_processor(filename_in, filename_out, process_frame_difference_full,\n",
        "                max_time=10, draw_mode=0)\n",
        "\n",
        "# Mostrar el video resultante\n",
        "media.show_video(media.read_video(filename_out), fps=30)"
      ],
      "metadata": {
        "id": "SdS9-ME1jSLY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def process_sparse_optical_flow(new_image, prev_image):\n",
        "    # Preparamos las imagenes de trabajo\n",
        "    new_gray = cv2.cvtColor(new_image, cv2.COLOR_BGR2GRAY)\n",
        "    prev_gray_image = cv2.cvtColor(prev_image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Verificar si ya se han detectado las características de Shi-Tomasi\n",
        "    if not hasattr(process_sparse_optical_flow, \"shi_tomasi_done\"):\n",
        "        # Definir parámetros para la detección de esquinas de Shi-Tomasi\n",
        "        feature_params = dict(maxCorners=300, qualityLevel=0.2, minDistance=2, blockSize=7)\n",
        "        # Detectar puntos característicos en la imagen\n",
        "        process_sparse_optical_flow.prev_points = cv2.goodFeaturesToTrack(new_gray, mask=None, **feature_params)\n",
        "        # Crear una máscara para dibujar el flujo óptico\n",
        "        process_sparse_optical_flow.mask = np.zeros_like(new_image)\n",
        "        # Marcar que se ha completado la detección de Shi-Tomasi\n",
        "        process_sparse_optical_flow.shi_tomasi_done = True\n",
        "\n",
        "    # Continuar si se ha completado la detección de Shi-Tomasi\n",
        "    if process_sparse_optical_flow.shi_tomasi_done:\n",
        "        prev_points = process_sparse_optical_flow.prev_points\n",
        "        mask = process_sparse_optical_flow.mask\n",
        "\n",
        "    # Parámetros para el flujo óptico de Lucas-Kanade\n",
        "    lk_params = dict(winSize=(15, 15), maxLevel=2,\n",
        "                     criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03))\n",
        "\n",
        "    # Calcular el flujo óptico de Lucas-Kanade\n",
        "    new_points, status, error = cv2.calcOpticalFlowPyrLK(prev_gray_image, new_gray, prev_points, None, **lk_params)\n",
        "    # Filtrar puntos buenos\n",
        "    good_old = prev_points[status == 1]\n",
        "    good_new = new_points[status == 1]\n",
        "    color = (0, 255, 0)  # Color para el dibujo\n",
        "    # Dibujar el movimiento (flujo óptico)\n",
        "    for i, (new, old) in enumerate(zip(good_new, good_old)):\n",
        "        a, b = new.astype(int).ravel()\n",
        "        c, d = old.astype(int).ravel()\n",
        "        mask = cv2.line(mask, (a, b), (c, d), color, 2)\n",
        "        new_image = cv2.circle(new_image, (a, b), 3, color, -1)\n",
        "\n",
        "    # Combinar la imagen actual con las líneas de flujo óptico dibujadas\n",
        "    output = cv2.add(new_image, mask)\n",
        "    # Actualizar puntos para el siguiente cuadro\n",
        "    process_sparse_optical_flow.prev_points = good_new.reshape(-1, 1, 2)\n",
        "    return output\n",
        "\n"
      ],
      "metadata": {
        "id": "84mYWY2Ns6to"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Nombres de los archivos de video de entrada y salida\n",
        "filename_in = '/content/cochera2.mp4'\n",
        "filename_out = 'cochera_sparse_optical_flow.mp4'\n",
        "\n",
        "# Llamar a la función para procesar el video\n",
        "video_processor(filename_in, filename_out, process_sparse_optical_flow,\n",
        "                max_time=10)\n",
        "\n",
        "# Mostrar el video resultante\n",
        "media.show_video(media.read_video(filename_out), fps=30)"
      ],
      "metadata": {
        "id": "MLcZ5MjduDhV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Función para procesar el flujo óptico denso\n",
        "def process_dense_optical_flow(new_image, prev_image):\n",
        "    # Convierte la nueva imagen a escala de grises\n",
        "    gray = cv2.cvtColor(new_image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    if not hasattr(process_dense_optical_flow, \"init_done\"):\n",
        "        process_dense_optical_flow.prev_gray = cv2.cvtColor(new_image, cv2.COLOR_BGR2GRAY)\n",
        "        process_dense_optical_flow.mask = np.zeros_like(new_image)\n",
        "        process_dense_optical_flow.mask[..., 1] = 255\n",
        "        process_dense_optical_flow.init_done = True\n",
        "\n",
        "    if process_dense_optical_flow.init_done:\n",
        "        prev_gray = process_dense_optical_flow.prev_gray\n",
        "        mask = process_dense_optical_flow.mask\n",
        "\n",
        "    # Calcula el flujo óptico\n",
        "    flow = cv2.calcOpticalFlowFarneback(prev_gray, gray, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
        "    # Computa magnitud y ángulo de los vectores 2D\n",
        "    magnitude, angle = cv2.cartToPolar(flow[..., 0], flow[..., 1])\n",
        "    # Establece el tono de la imagen según la dirección del flujo óptico\n",
        "    mask[..., 0] = angle * 180 / np.pi / 2\n",
        "    # Establece el valor de la imagen según la magnitud del flujo óptico\n",
        "    mask[..., 2] = cv2.normalize(magnitude, None, 0, 255, cv2.NORM_MINMAX)\n",
        "    # Convierte de HSV a RGB\n",
        "    rgb = cv2.cvtColor(mask, cv2.COLOR_HSV2BGR)\n",
        "    # Actualiza la imagen previa a gris\n",
        "    process_dense_optical_flow.prev_grayprev_gray = gray.copy()\n",
        "    return rgb\n",
        "\n"
      ],
      "metadata": {
        "id": "jjJ9oVjSvKbO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Nombres de los archivos de video de entrada y salida\n",
        "filename_in = '/content/cochera2.mp4'\n",
        "filename_out = 'cochera_dense_optical_flow.mp4'\n",
        "\n",
        "# Llamar a la función para procesar el video\n",
        "video_processor(filename_in, filename_out, process_dense_optical_flow,\n",
        "                max_time=20)\n",
        "\n",
        "# Mostrar el video resultante\n",
        "media.show_video(media.read_video(filename_out), fps=30)"
      ],
      "metadata": {
        "id": "uuLRg-YUvLoV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3etDY0MZ5Mne"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. (Entrega obligatoria individual en repo) Explique cuál es diferencia entre localización de objetos y clasificación de imágenes. Muestre ejemplos de ello."
      ],
      "metadata": {
        "id": "aWi2sFK46l29"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "La localización de objetos se centra en identificar y ubicar objetos específicos dentro de una imagen.\n",
        "La clasificación de imágenes se centra en asignar una etiqueta o categoría a una imagen completa en función de su contenido general.\n",
        "\n",
        "\n",
        "Basicamente lo que sucede es que se usan para tareas dferentes. Uno se usa para encontrar objetos dentro de una imagen y el otro se usa para clasificiar imagenes en ciertas etiquetas"
      ],
      "metadata": {
        "id": "UakYSME36qfE"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "m-mFNwJX6xfG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}